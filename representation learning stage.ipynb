{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-04-07T08:14:28.100582Z",
     "iopub.status.busy": "2024-04-07T08:14:28.100152Z",
     "iopub.status.idle": "2024-04-07T08:14:28.137684Z",
     "shell.execute_reply": "2024-04-07T08:14:28.136562Z",
     "shell.execute_reply.started": "2024-04-07T08:14:28.100533Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting cv_example.py\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "import math\n",
    "import torch.distributed as dist\n",
    "from torch.multiprocessing import Process\n",
    "\n",
    "############################################# 21\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "#  Few-shot parameters  #\n",
    "parser.add_argument('--data_name', default='miniImageNet', help='miniImageNet| tieredImageNet')\n",
    "parser.add_argument('--method_name', default='KL', help=' Wass | Wass_CMS | KL | KL_CMS | ADM ')\n",
    "parser.add_argument('--mode', default='train', help='train|val|test')\n",
    "parser.add_argument('--outf', default='./results/')\n",
    "parser.add_argument('--workers', type=int, default=0)\n",
    "parser.add_argument('--way_num', type=int, default=5, help='the number of way/class')\n",
    "parser.add_argument('--shot_num', type=int, default=1, help='the number of shot')\n",
    "parser.add_argument('--query_num', type=int, default=15, help='the number of queries')\n",
    "parser.add_argument('--train_num', type=int, default=10, help='pretrain number, default=10')\n",
    "#  Few-shot parameters  #\n",
    "parser.add_argument('--epochs', type=int, default=50, help='the total number of training epoch')\n",
    "parser.add_argument('--start_epoch', default=0, type=int, help='manual epoch number (useful on restarts)')\n",
    "parser.add_argument('--lr', type=float, default=0.1, help='learning rate, default=0.005')\n",
    "parser.add_argument('--lr2', type=float, default=100, help='learning rate, default=0.005')\n",
    "parser.add_argument('--adam', action='store_true', default=True, help='use adam optimizer')\n",
    "parser.add_argument('--batch-size', type=int, default=128)\n",
    "parser.add_argument('--print_freq', '-p', default=10, type=int, metavar='N', help='print frequency (default: 100)')\n",
    "parser.add_argument('-f', type=str, default=\"读取额外的参数\")\n",
    "parser.add_argument('--freeze-layers', type=bool, default=False)\n",
    "# 不要改该参数，系统会自动分配\n",
    "parser.add_argument('--device', default='cuda', help='device id (i.e. 0 or 0,1 or cpu)')\n",
    "# 开启的进程数(注意不是线程),在单机中指使用GPU的数量\n",
    "parser.add_argument('--world-size', default=4, type=int,\n",
    "                    help='number of distributed processes')\n",
    "parser.add_argument('--dist-url', default='env://', help='url used to set up distributed training')\n",
    "\n",
    "opt = parser.parse_args(args=[])\n",
    "\n",
    "if 'RANK' in os.environ and 'WORLD_SIZE' in os.environ:\n",
    "    opt.rank = int(os.environ[\"RANK\"])\n",
    "    opt.world_size = int(os.environ['WORLD_SIZE'])\n",
    "    opt.gpu = int(os.environ['LOCAL_RANK'])\n",
    "elif 'SLURM_PROCID' in os.environ:\n",
    "    opt.rank = int(os.environ['SLURM_PROCID'])\n",
    "    opt.gpu = opt.rank % torch.cuda.device_count()\n",
    "else:\n",
    "    print('Not using distributed mode')\n",
    "    opt.distributed = False\n",
    "\n",
    "\n",
    "opt.distributed = True\n",
    "\n",
    "torch.cuda.set_device(opt.gpu)\n",
    "opt.dist_backend = 'nccl'  # 通信后端，nvidia GPU推荐使用NCCL\n",
    "print('| distributed init (rank {}): {}'.format(\n",
    "    opt.rank, opt.dist_url), flush=True)\n",
    "dist.init_process_group(backend=opt.dist_backend, init_method=opt.dist_url,\n",
    "                        world_size=opt.world_size, rank=opt.rank)\n",
    "dist.barrier()\n",
    "\n",
    "device = torch.device(opt.device)\n",
    "\n",
    "################################################################\n",
    "\n",
    "data_dir = \"\"\n",
    "\n",
    "class GaussianBlur(object):\n",
    "    \"\"\"Gaussian blur augmentation in SimCLR https://arxiv.org/abs/2002.05709\"\"\"\n",
    "\n",
    "    def __init__(self, sigma=[.1, 2.]):\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __call__(self, x):\n",
    "        sigma = random.uniform(self.sigma[0], self.sigma[1])\n",
    "        x = x.filter(ImageFilter.GaussianBlur(radius=sigma))\n",
    "        return x\n",
    "\n",
    "\n",
    "mocoAug = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224, scale=(0.2, 1.)),\n",
    "#     transforms.RandomApply([\n",
    "#         transforms.ColorJitter(0.2, 0.2, 0.2, 0.1)  # not strengthened\n",
    "#     ], p=0.8),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomApply([GaussianBlur([.1, 2.])], p=0.5),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((84, 84)),\n",
    "])\n",
    "\n",
    "\n",
    "supervisedAug = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomGrayscale(p=0.2),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((84, 84)),\n",
    "])\n",
    "\n",
    "trans_val = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((84, 84)),\n",
    "])\n",
    "\n",
    "def RGB_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "\n",
    "def load_data(data_path):\n",
    "    data_dict = {}\n",
    "    data_list = []\n",
    "    for folder_name in os.listdir(data_path):\n",
    "        data_dict[folder_name] = []\n",
    "        folder_path = os.path.join(data_path, folder_name)\n",
    "        for filename in os.listdir(folder_path):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            data_list.append((image_path, folder_name))\n",
    "            data_dict[folder_name].append(image_path)\n",
    "    class_list = data_dict.keys()\n",
    "    return data_list, data_dict, class_list\n",
    "\n",
    "class FewShotDataSet(Dataset):\n",
    "    def __init__(self, data_dir, phase='train', loader=RGB_loader):\n",
    "        super(FewShotDataSet, self).__init__()\n",
    "        IMAGE_PATH = \"\"\n",
    "        self.loader = loader\n",
    "        if phase == 'train':\n",
    "            csv_path = \"\"\n",
    "        elif phase == 'val':\n",
    "            csv_path = \"\"\n",
    "        else:\n",
    "            csv_path = \"\"\n",
    "\n",
    "            \n",
    "        data_list = []\n",
    "        data_dict = {}\n",
    "        \n",
    "        lines = [x.strip() for x in open(csv_path, 'r').readlines()][1:]\n",
    "\n",
    "        self.wnids = []\n",
    "\n",
    "        for l in lines:\n",
    "            context = l.split(',')\n",
    "            name = context[0]\n",
    "            wnid = context[1]\n",
    "            path = osp.join(IMAGE_PATH, name)\n",
    "            data_list.append((path, wnid))\n",
    "            if wnid not in data_dict:\n",
    "                data_dict[wnid] = []\n",
    "            data_dict[wnid].append(path)\n",
    "        class_list = data_dict.keys()\n",
    "            \n",
    "        \n",
    "        self.data_list = data_list\n",
    "        self.data_dict = data_dict\n",
    "        self.class_list = sorted(list(class_list))\n",
    "        self.label2Int = {item: idx for idx, item in enumerate(self.class_list)}\n",
    "        self.num_cats = len(self.class_list)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_item, class_name = self.data_list[item]\n",
    "        label = self.label2Int[class_name]\n",
    "        fn = os.path.join(img_item)\n",
    "        img = self.loader(fn)\n",
    "        img = torch.cat((mocoAug(img).unsqueeze(0), mocoAug(img).unsqueeze(0), supervisedAug(img).unsqueeze(0)), dim=0)\n",
    "        return img, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(len(self.data_list))\n",
    "\n",
    "def get_dataloader(opt, mode):\n",
    "    dataset = FewShotDataSet(data_dir, phase=mode)\n",
    "    if mode == 'train':\n",
    "        loader = MetaDataloader(dataset, opt, mode)     # opt.episode_train_num默认值10000\n",
    "    elif mode == 'val':\n",
    "        loader = MetaDataloader(dataset, opt, mode)\n",
    "    elif mode == 'test':\n",
    "        loader = MetaDataloader(dataset, opt, mode)\n",
    "    else:\n",
    "        raise ValueError('Mode ought to be in [train, val, test]')\n",
    "    return loader\n",
    "\n",
    "class MetaDataloader(object):\n",
    "    def __init__(self, dataset, opt, mode):\n",
    "        self.dataset = dataset\n",
    "#         self.img_root = dataset.img_path\n",
    "        self.loader = dataset.loader\n",
    "\n",
    "        self.way_num = opt.way_num\n",
    "        self.shot_num = opt.shot_num\n",
    "        self.query_num = opt.query_num\n",
    "        # self.batch_size = opt.batch_size\n",
    "        # self.epoch_size = opt.epoch_size\n",
    "        self.num_workers = int(opt.workers)\n",
    "        # self.current_epoch = opt.current_epoch\n",
    "        if mode == 'train':\n",
    "            self.shuffle = True\n",
    "        else:\n",
    "            self.shuffle = False\n",
    "\n",
    "    def sampleImageIdsFrom(self, cat_id, sample_size=1):  # 根据类id采样某一类下个数为sample_size大小的样本\n",
    "        assert (cat_id in self.dataset.data_dict)\n",
    "        assert (len(self.dataset.data_dict[cat_id]) >= sample_size)\n",
    "        # Note: random.sample samples elements without replacement.\n",
    "        return random.sample(self.dataset.data_dict[cat_id], sample_size)\n",
    "\n",
    "    def sampleCategories(self, sample_size=1):  # 对数据集中的类进行采样\n",
    "        class_list = self.dataset.class_list\n",
    "        assert (len(class_list) >= sample_size)\n",
    "        return random.sample(class_list, sample_size)  # 从class_list中随机获得长度为sample_size的种类\n",
    "\n",
    "    def sampleSupQuery(self, categories, query_num, shot_num):\n",
    "        if len(categories) == 0:\n",
    "            return [], []\n",
    "        nCategories = len(categories)\n",
    "        Query_imgs = []\n",
    "        Support_imgs = []\n",
    "\n",
    "        for idx in range(len(categories)):\n",
    "            img_ids = self.sampleImageIdsFrom(\n",
    "                categories[idx],\n",
    "                sample_size=(query_num + shot_num)\n",
    "            )\n",
    "            imgs_novel = img_ids[:query_num]\n",
    "            imgs_exemplar = img_ids[query_num:]\n",
    "\n",
    "            Query_imgs += [(img_id, idx) for img_id in imgs_novel]\n",
    "            Support_imgs += [(img_id, idx) for img_id in imgs_exemplar]\n",
    "\n",
    "        assert (len(Query_imgs) == nCategories * query_num)\n",
    "        assert (len(Support_imgs) == nCategories * shot_num)\n",
    "\n",
    "        return Query_imgs, Support_imgs\n",
    "\n",
    "    def sampleEpisode(self):\n",
    "        categories = self.sampleCategories(self.way_num)\n",
    "        Query_imgs, Support_imgs = self.sampleSupQuery(categories, self.query_num, self.shot_num)\n",
    "        return Query_imgs, Support_imgs\n",
    "\n",
    "    def createExamplesTensorData(self, examples):\n",
    "        images = torch.stack(\n",
    "            [trans_val(self.loader(img_name)) for img_name, _ in examples], dim=0)\n",
    "        labels = torch.tensor([label for _, label in examples])\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "    def load_function(self, iter_idx):\n",
    "        Query_imgs, Support_imgs = self.sampleEpisode()\n",
    "        Xt, Yt = self.createExamplesTensorData(Query_imgs)\n",
    "        Xe, Ye = self.createExamplesTensorData(Support_imgs)\n",
    "        return Xt, Yt, Xe, Ye\n",
    "\n",
    "    def get_iterator(self, index):\n",
    "        rand_seed = index\n",
    "        random.seed(rand_seed)\n",
    "        np.random.seed(rand_seed)\n",
    "        Xt, Yt, Xe, Ye = self.load_function(index)\n",
    "\n",
    "        return Xt, Yt, Xe, Ye\n",
    "\n",
    "    def __call__(self, index):\n",
    "        return self.get_iterator(index)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 0\n",
    "    \n",
    "    \n",
    "#######################################################################################\n",
    "\n",
    "def conv3x3(in_channels, out_channels):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False)\n",
    "\n",
    "def conv1x1(in_channels, out_channels):\n",
    "    return nn.Conv2d(in_channels, out_channels, kernel_size=1, bias=False)\n",
    "\n",
    "class Conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c, kernel=(1, 1), stride=(1, 1), padding=(0, 0), groups=1):\n",
    "        super(Conv_block, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_c, out_channels=out_c, kernel_size=kernel, groups=groups, stride=stride, padding=padding, bias=False)\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, downsample):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(in_channels, out_channels)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.LeakyReLU(0.2)\n",
    "        self.conv2 = conv3x3(out_channels, out_channels)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv3 = conv3x3(out_channels, out_channels)\n",
    "        self.bn3 = nn.BatchNorm2d(out_channels)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet12(nn.Module):\n",
    "    def __init__(self, channels):\n",
    "        super(ResNet12, self).__init__()\n",
    "\n",
    "        self.inplanes = 3\n",
    "\n",
    "        self.layer1 = self._make_layer(channels[0])\n",
    "        self.layer2 = self._make_layer(channels[1])\n",
    "        self.layer3 = self._make_layer(channels[2])\n",
    "        self.layer4 = self._make_layer(channels[3])\n",
    "\n",
    "        self.out_dims = channels[3]\n",
    "\n",
    "    def _make_layer(self, planes):\n",
    "        downsample = nn.Sequential(\n",
    "            conv1x1(self.inplanes, planes),\n",
    "            nn.BatchNorm2d(planes),\n",
    "        )\n",
    "        block = ResBlock(self.inplanes, planes, downsample)\n",
    "        self.inplanes = planes\n",
    "        return block\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        return x\n",
    "\n",
    "def resnet12():\n",
    "    return ResNet12([64, 128, 256, 512])\n",
    "\n",
    "def resnet12_wide():\n",
    "    return ResNet12([64, 160, 320, 640])\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    # print(classname)\n",
    "    if classname.find('Conv') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, 0.02)  # 网络初始化，normal_实现基于正态分布的初始化参数\n",
    "    elif classname.find('Linear') != -1:\n",
    "        init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "\n",
    "def get_model(pre_train=False, model_dir=None, num_class=80, dim=128):\n",
    "    model = featureAugNet(num_class, dim)\n",
    "    #     model.apply(weights_init_normal)\n",
    "    if pre_train:\n",
    "        model.load_state_dict(torch.load(model_dir)['state_dict'])\n",
    "    return model\n",
    "\n",
    "\n",
    "class BaseEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseEncoder, self).__init__()\n",
    "        self.extractor = resnet12_wide()\n",
    "        self.pooling = nn.AvgPool2d(kernel_size=5, stride=5)\n",
    "        self.linear = nn.Linear(640, 128)\n",
    "        self.act = nn.LeakyReLU(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extractor(x)\n",
    "        feature_pool = self.pooling(x)\n",
    "        x = feature_pool.view(feature_pool.size(0), -1)\n",
    "        out = self.act(self.linear(x))\n",
    "        return x, out\n",
    "    \n",
    "class BaseEncoderClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BaseEncoderClass, self).__init__()\n",
    "        self.extractor = resnet12_wide()\n",
    "        self.pooling = nn.AvgPool2d(kernel_size=5, stride=5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.extractor(x)\n",
    "        feature_pool = self.pooling(x)\n",
    "        x = feature_pool.view(feature_pool.size(0), -1)\n",
    "        return x\n",
    "\n",
    "class distLinear(nn.Module):\n",
    "    def __init__(self, indim, outdim):\n",
    "        super(distLinear, self).__init__()\n",
    "        self.L = nn.Linear(indim, outdim, bias=False)\n",
    "            \n",
    "    def forward(self, x):\n",
    "        self.L.weight.data = nn.functional.normalize(self.L.weight.data, dim=1)\n",
    "        return 10*self.L(x)\n",
    "    \n",
    "class linearC(nn.Module):\n",
    "    def __init__(self, indim, outdim):\n",
    "        super(linearC, self).__init__()\n",
    "        self.L = nn.Linear(indim, outdim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.L(x)\n",
    "    \n",
    "class MoCo(nn.Module):\n",
    "    def __init__(self, base_encoder, dim=128, K=2048, m=0.999, T=0.1):\n",
    "        super(MoCo, self).__init__()\n",
    "        self.K = K\n",
    "        self.T = T\n",
    "        self.m = m\n",
    "\n",
    "        self.encoder_q = base_encoder()\n",
    "        self.encoder_k = base_encoder()\n",
    "\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data.copy_(param_q.data)\n",
    "            param_k.requires_grad = False\n",
    "\n",
    "        self.register_buffer(\"queue\", torch.randn(dim, K))\n",
    "        self.queue = nn.functional.normalize(self.queue, dim=0)\n",
    "        self.register_buffer(\"queue_ptr\", torch.zeros(1, dtype=torch.long))\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _momentum_update_key_encoder(self):\n",
    "        for param_q, param_k in zip(self.encoder_q.parameters(), self.encoder_k.parameters()):\n",
    "            param_k.data = param_k.data * self.m + param_q.data * (1. - self.m)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _dequeue_and_enqueue(self, keys):\n",
    "        keys = concat_all_gather(keys)\n",
    "        batch_size = keys.shape[0]\n",
    "        ptr = int(self.queue_ptr)\n",
    "        assert self.K % batch_size == 0  # for simplicity\n",
    "        self.queue[:, ptr:ptr + batch_size] = keys.T\n",
    "        ptr = (ptr + batch_size) % self.K  # move pointer\n",
    "\n",
    "        self.queue_ptr[0] = ptr\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_shuffle_ddp(self, x):\n",
    "        \"\"\"\n",
    "        Batch shuffle, for making use of BatchNorm.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # random shuffle index\n",
    "        idx_shuffle = torch.randperm(batch_size_all).to(device)\n",
    "\n",
    "        # broadcast to all gpus\n",
    "        torch.distributed.broadcast(idx_shuffle, src=0)\n",
    "\n",
    "        # index for restoring\n",
    "        idx_unshuffle = torch.argsort(idx_shuffle)\n",
    "\n",
    "        # shuffled index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_shuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this], idx_unshuffle\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _batch_unshuffle_ddp(self, x, idx_unshuffle):\n",
    "        \"\"\"\n",
    "        Undo batch shuffle.\n",
    "        *** Only support DistributedDataParallel (DDP) model. ***\n",
    "        \"\"\"\n",
    "        # gather from all gpus\n",
    "        batch_size_this = x.shape[0]\n",
    "        x_gather = concat_all_gather(x)\n",
    "        batch_size_all = x_gather.shape[0]\n",
    "\n",
    "        num_gpus = batch_size_all // batch_size_this\n",
    "\n",
    "        # restored index for this gpu\n",
    "        gpu_idx = torch.distributed.get_rank()\n",
    "        idx_this = idx_unshuffle.view(num_gpus, -1)[gpu_idx]\n",
    "\n",
    "        return x_gather[idx_this]\n",
    "        \n",
    "    def forward(self, im_q, im_k):\n",
    "        q_high, q = self.encoder_q(im_q)\n",
    "        q = nn.functional.normalize(q, dim=1)\n",
    "        # feature = q.clone()\n",
    "        with torch.no_grad():\n",
    "            self._momentum_update_key_encoder()\n",
    "            im_k, idx_unshuffle = self._batch_shuffle_ddp(im_k)\n",
    "            _, k = self.encoder_k(im_k)\n",
    "            k = nn.functional.normalize(k, dim=1)\n",
    "            k = self._batch_unshuffle_ddp(k, idx_unshuffle)\n",
    "\n",
    "        l_pos = torch.einsum('nc,nc->n', [q, k]).unsqueeze(-1)\n",
    "        l_neg = torch.einsum('nc,ck->nk', [q, self.queue.clone().detach()])\n",
    "\n",
    "        logits = torch.cat([l_pos, l_neg], dim=1)\n",
    "        logits /= self.T\n",
    "        self._dequeue_and_enqueue(k)\n",
    "\n",
    "        return q_high, logits\n",
    "\n",
    "@torch.no_grad()\n",
    "def concat_all_gather(tensor):\n",
    "    \"\"\"\n",
    "    Performs all_gather operation on the provided tensors.\n",
    "    *** Warning ***: torch.distributed.all_gather has no gradient.\n",
    "    \"\"\"\n",
    "    tensors_gather = [torch.ones_like(tensor)\n",
    "        for _ in range(torch.distributed.get_world_size())]\n",
    "    torch.distributed.all_gather(tensors_gather, tensor.contiguous(), async_op=False)\n",
    "\n",
    "    output = torch.cat(tensors_gather, dim=0)\n",
    "    return output   \n",
    "\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "class classFeatureExtractor(nn.Module):\n",
    "    def __init__(self, base_enceoder, num_classes=64, dim=640):\n",
    "        super(classFeatureExtractor, self).__init__()\n",
    "        self.base_encoder = base_enceoder()\n",
    "        self.classifier = distLinear(dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_encoder(x)\n",
    "        x = nn.functional.normalize(x)\n",
    "        out = self.classifier(x)\n",
    "        return x, out\n",
    "\n",
    "    \n",
    "class featureAugNet(nn.Module):\n",
    "    def __init__(self, num_classes=100, dim=640):\n",
    "        super(featureAugNet, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.instFeatExt = MoCo(BaseEncoder, dim=128, K=2048, m=0.999, T=0.1)\n",
    "        self.classFeatExt = classFeatureExtractor(BaseEncoderClass, num_classes=num_classes, dim=dim)\n",
    "        self.classifier = distLinear(dim, num_classes)\n",
    "   \n",
    "    @torch.no_grad()\n",
    "    def update_classifier(self):\n",
    "        for param_q, param_k in zip(self.classFeatExt.classifier.parameters(), self.classifier.parameters()):\n",
    "            param_k.data = param_q.data\n",
    "    \n",
    "\n",
    "    def forward(self, im_q, im_k, im_s):\n",
    "#         batch_size = labels.shape[0]\n",
    "#         kl_loss = torch.tensor(0.).to(device)\n",
    "        q_high, logits_u = self.instFeatExt(im_q, im_k)\n",
    "        q_high = nn.functional.normalize(q_high, dim=1)\n",
    "        self.update_classifier()\n",
    "        logits_us = self.classifier(q_high)\n",
    "        s_high, logits_s = self.classFeatExt(im_s)\n",
    "        return q_high, logits_u, logits_us, s_high, logits_s\n",
    "\n",
    "\n",
    "def MoCoModel():\n",
    "    return MoCo(BaseEncoder, dim=128, K=2048, m=0.999, T=0.1)\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "\n",
    "def adjust_learning_rate(opt, optimizer, epoch, F_txt):\n",
    "\t\"\"\"Sets the learning rate to the initial LR decayed by 2 every 10 epoches\"\"\"\n",
    "\tlr = opt.lr * (0.2 ** (epoch // 35))\n",
    "\tprint('Learning rate: %f' %lr)\n",
    "\tprint('Learning rate: %f' %lr, file=F_txt)\n",
    "\tfor param_group in optimizer.param_groups:\n",
    "\t\tparam_group['lr'] = lr\n",
    "\n",
    "# def adjust_learning_rate(opt, optimizer, epoch, F_txt):\n",
    "#     lr = opt.lr * (0.5 ** (epoch // 10))\n",
    "#     lr2 = opt.lr2 * (0.5 ** (epoch // 5))\n",
    "#     print('learning rate: %f' % lr)\n",
    "#     print('learning rate: %f' % lr2)\n",
    "#     print('Learning rate: %f' % lr, file=F_txt)\n",
    "#     optimizer.param_groups[0]['lr'] = lr\n",
    "#     optimizer.param_groups[1]['lr'] = lr\n",
    "#     optimizer.param_groups[2]['lr'] = lr2\n",
    "#     for param_group in optimizer.param_groups:\n",
    "#         param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "\ta = [1.0*np.array(data[i]) for i in range(len(data))]\n",
    "\tn = len(a)\n",
    "\tm, se = np.mean(a), scipy.stats.sem(a)\n",
    "\th = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "\treturn m, h\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    with torch.no_grad():\n",
    "        maxk = max(topk)\n",
    "        batch_size = target.size(0)\n",
    "\n",
    "        _, pred = output.topk(maxk, 1, True, True)\n",
    "        pred = pred.t()\n",
    "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "        res = []\n",
    "\n",
    "        for k in topk:\n",
    "            correct_k = correct[:k].contiguous().view(-1).float().sum(0, keepdim=True).mul_(100.0 / batch_size).cpu().detach().numpy()\n",
    "            res.append(correct_k)\n",
    "        return res  # 返回topk的准确率\n",
    "\n",
    "\n",
    "def set_save_path(opt):\n",
    "    \"\"\"\n",
    "    settings of the save path\n",
    "    \"\"\"\n",
    "    opt.outf = 'Shot'\n",
    "\n",
    "    if not os.path.exists(opt.outf):\n",
    "        os.makedirs(opt.outf)\n",
    "\n",
    "\n",
    "    # save the opt and results to txt file\n",
    "    txt_save_path = os.path.join(opt.outf, 'opt_resutls.txt')\n",
    "    F_txt = open(txt_save_path, 'a+')\n",
    "\n",
    "    return opt.outf, F_txt\n",
    "\n",
    "\n",
    "def set_save_test_path(opt, finetune=False):\n",
    "    \"\"\"\n",
    "    Settings of the save path\n",
    "    \"\"\"\n",
    "    if not os.path.exists(opt.outf):\n",
    "        os.makedirs(opt.outf)\n",
    "\n",
    "    # save the opt and results to txt file\n",
    "    if finetune:\n",
    "        txt_save_path = os.path.join(opt.outf, 'Test_Finetune_resutls.txt')\n",
    "    else:\n",
    "        txt_save_path = os.path.join(opt.outf, 'Test_resutls.txt')\n",
    "    F_txt_test = open(txt_save_path, 'a+')\n",
    "\n",
    "    return F_txt_test\n",
    "\n",
    "\n",
    "def get_resume_file(checkpoint_dir, F_txt):\n",
    "    if os.path.isfile(checkpoint_dir):\n",
    "        print(\"=> loading checkpoint '{}'\".format(checkpoint_dir))\n",
    "        print(\"=> loading checkpoint '{}'\".format(checkpoint_dir), file=F_txt)\n",
    "        checkpoint = torch.load(checkpoint_dir)\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(checkpoint_dir, checkpoint['epoch_index']))\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\".format(checkpoint_dir, checkpoint['epoch_index']), file=F_txt)\n",
    "\n",
    "        return checkpoint\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(checkpoint_dir))\n",
    "        print(\"=> no checkpoint found at '{}'\".format(checkpoint_dir), file=F_txt)\n",
    "\n",
    "        return None\n",
    "    \n",
    "##############################################################################################\n",
    "def train(train_loader, model, criterions, optimizer, batch_size, epoch_index, dataset_length, F_txt, device, rank):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1_s = AverageMeter()\n",
    "    top1_u = AverageMeter()\n",
    "    end = time.time()\n",
    "    train_iterator = iter(train_loader)\n",
    "    mse_criterion = criterions[1]\n",
    "    entropy_criterion = criterions[0]\n",
    "    iter_length = int(dataset_length / batch_size)\n",
    "    sup_align_loss = torch.tensor(0.).to(device)\n",
    "    sup_align_loss.requires_grad = True\n",
    "    recon_loss = torch.tensor(0.).to(device)\n",
    "    recon_loss.requires_grad = True\n",
    "    for iter_num in range(iter_length):     # 300 = len(dataset) / batchsize\n",
    "        try:\n",
    "            imgs, labels = next(train_iterator)\n",
    "        except StopIteration:\n",
    "            train_iterator = iter(train_loader)\n",
    "            imgs, labels = next(train_iterator)\n",
    "        imgs = imgs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        batch_size = imgs.shape[0]\n",
    "        im_q, im_k, im_s = imgs[:, 0, ...], imgs[:, 1, ...], imgs[:, 2, ...]\n",
    "        data_time.update(time.time() - end)\n",
    "        feature_u, logits_u, logits_us, feature_s, logits_s = model(im_q, im_k, im_s)\n",
    "        labels_u = torch.zeros(logits_u.shape[0], dtype=torch.long).to(device)\n",
    "        # 计算有监督无监督特征对齐损失\n",
    "        feature_u_dnorm = nn.functional.normalize(feature_u-torch.mean(feature_u, dim=1, keepdim=True), dim=1)\n",
    "        feature_s_dnorm = nn.functional.normalize(feature_s-torch.mean(feature_s, dim=1, keepdim=True), dim=1)\n",
    "        u_s_crossalign_loss = -1.5*torch.mean(torch.einsum('nc,nc->n', [feature_u_dnorm, feature_s_dnorm])) - 0.5*torch.mean(torch.einsum('nc,nc->n', [feature_u, feature_s]))\n",
    "        # 特征重建损失\n",
    "#         if epoch_index > 35:\n",
    "#             recon_features = nn.functional.normalize(recon_features, dim=1)\n",
    "#             recon_loss = 10*mse_criterion(recon_features, feature_u) - 10*torch.mean(torch.einsum('nc,nc->n', [recon_features, feature_u.detach()]))\n",
    "        # entropy loss\n",
    "        entropy_loss = entropy_criterion(logits_s, labels)\n",
    "        entropy_loss_u = entropy_criterion(logits_us, labels)\n",
    "#         entropy_loss_recon = entropy_criterion(logits_recon, labels)\n",
    "        # infoNCE\n",
    "        infoNCELoss = entropy_criterion(logits_u, labels_u)\n",
    "        # all loss\n",
    "        loss = entropy_loss + infoNCELoss + entropy_loss_u + u_s_crossalign_loss\n",
    "        prec1_s = accuracy(logits_s, labels, topk=(1,))\n",
    "        prec1_u = accuracy(logits_us, labels, topk=(1,))\n",
    "        losses.update(loss.item(), batch_size)\n",
    "        top1_s.update(prec1_s[0].item(), batch_size)\n",
    "        top1_u.update(prec1_u[0].item(), batch_size)\n",
    "        optimizer.zero_grad()\n",
    "#         print(\"######################################################before####################################\")\n",
    "#         print(model.module.intra_classMean.grad)\n",
    "        loss.backward()\n",
    "#         print(\"###################################################### after ####################################\")\n",
    "#         print(model.module.intra_classInfo.grad)\n",
    "        optimizer.step()\n",
    "#         ls = [name for name,para in model.named_parameters() if para.grad==None]\n",
    "#         print(ls)\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        # ============== print the intermediate results ==============#\n",
    "        if rank == 0:\n",
    "            if iter_num % opt.print_freq == 0 and iter_num != 0:\n",
    "                print('Eposide-({0}): [{1}/{2}]\\t'\n",
    "                      'entropy infonce u&s uc {3} {4} {5} {6}\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
    "                      'Prec1 {top1_s.avg:.3f} ({top1_u.avg:.3f})\\t'.format(epoch_index, iter_num, iter_length,\n",
    "                                                                      round(entropy_loss.item(), 3), round(infoNCELoss.item(), 3),\n",
    "                                                                      round(u_s_crossalign_loss.item(), 3), round(entropy_loss_u.item(), 3),\n",
    "                                                                      batch_time=batch_time,\n",
    "                                                                      data_time=data_time, loss=losses, top1_s=top1_s, top1_u=top1_u))\n",
    "\n",
    "                print('Eposide-({0}): [{1}/{2}]\\t'\n",
    "                      'entropy infonce u&s uc {3} {4} {5} {6}\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.3f} ({loss.avg:.3f})\\t'\n",
    "                      'Prec1 {top1_s.avg:.3f} ({top1_u.avg:.3f})\\t'.format(epoch_index, iter_num, iter_length,\n",
    "                                                                      round(entropy_loss.item(), 3), round(infoNCELoss.item(), 3),\n",
    "                                                                      round(u_s_crossalign_loss.item(), 3), round(entropy_loss_u.item(), 3),\n",
    "                                                                      batch_time=batch_time,\n",
    "                                                                      data_time=data_time, loss=losses, top1_s=top1_s, top1_u=top1_u), file=F_txt)\n",
    "\n",
    "    return losses\n",
    "\n",
    "###########################################################################\n",
    "def val_train(train_num, data, train_model, model, criterion, optimizer):\n",
    "    x, y = data[0], data[1]\n",
    "    # loss = torch.tensor(0.).to(device)\n",
    "    for i in range(train_num):\n",
    "        feat, logits = train_model.module.classFeatExt(x)       # 这里的优化器优化的模型参数应为未冻结的模型参数\n",
    "\n",
    "        logits = model(feat)\n",
    "        loss = criterion(logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "#         if i % 100 ==0:\n",
    "#             for param_group in optimizer.param_groups:\n",
    "#                 param_group['lr'] = param_group['lr']/5\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def val(train_model, criterion, epoch, rank):\n",
    "    top1_val = AverageMeter()\n",
    "    for task_num in range(1):\n",
    "        model = distLinear(indim=640, outdim=5).to(device)\n",
    "        checkpoint_path = \"dist_initial_weights.pt\"\n",
    "        if rank == 0:\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        dist.barrier()\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[opt.gpu])\n",
    "        val_optimizer = optim.Adam(model.parameters())\n",
    "        test_loader = get_dataloader(opt, 'val')\n",
    "        X_q, Y_q, X_s, Y_s = test_loader(10*epoch + task_num)     # 0 is rand seed\n",
    "        X_q, Y_q, X_s, Y_s = X_q.to(device), Y_q.to(device), X_s.to(device), Y_s.to(device)\n",
    "        query_nums = Y_q.shape[-1]\n",
    "        model.train()\n",
    "#         print(\"############################  Before Train  ################################\")\n",
    "#         print(model.L.weight)\n",
    "        model = val_train(30, [X_s, Y_s], train_model, model, criterion, val_optimizer)\n",
    "#         print(\"############################  After Train  ################################\")\n",
    "#         print(model.L.weight)\n",
    "        model.eval()\n",
    "        feats, _ = train_model.module.classFeatExt(X_q)\n",
    "        logit = model(feats)\n",
    "        prec1 = accuracy(logit, Y_q, topk=(1,))\n",
    "        top1_val.update(prec1[0].item(), query_nums)\n",
    "#         top1.update(prec1[0].item(), query_nums)\n",
    "        del val_optimizer\n",
    "        del model\n",
    "        if rank == 0:\n",
    "            print('Eposide-({0}): [{1}/{2}]\\t'\n",
    "                  'prec1 is {3}\\t'.format(epoch, task_num, 10, prec1[0].item()))\n",
    "    \n",
    "    if rank == 0:               \n",
    "#         print(\"测试结果为\" + str(top1.avg))\n",
    "        print(\"第%d代验证结果为\"%epoch_item + str(top1_val.avg))\n",
    "    return top1_val.avg\n",
    "    \n",
    "    \n",
    "def test(train_model, criterion, epoch, rank):\n",
    "    top1_val = AverageMeter()\n",
    "    for task_num in range(1):\n",
    "        model = distLinear(indim=640, outdim=5).to(device)\n",
    "        checkpoint_path = \"dist_initial_weights.pt\"\n",
    "        if rank == 0:\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "        dist.barrier()\n",
    "        model.load_state_dict(torch.load(checkpoint_path, map_location=device))\n",
    "        model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[opt.gpu])\n",
    "        val_optimizer = optim.Adam(model.parameters())\n",
    "        test_loader = get_dataloader(opt, 'test')\n",
    "        X_q, Y_q, X_s, Y_s = test_loader(10*epoch + task_num)     # 0 is rand seed\n",
    "        X_q, Y_q, X_s, Y_s = X_q.to(device), Y_q.to(device), X_s.to(device), Y_s.to(device)\n",
    "        query_nums = Y_q.shape[-1]\n",
    "        model.train()\n",
    "#         print(\"############################  Before Train  ################################\")\n",
    "#         print(model.L.weight)\n",
    "        model = val_train(30, [X_s, Y_s], train_model, model, criterion, val_optimizer)\n",
    "#         print(\"############################  After Train  ################################\")\n",
    "#         print(model.L.weight)\n",
    "        model.eval()\n",
    "        feats, _ = train_model.module.classFeatExt(X_q)\n",
    "        logit = model(feats)\n",
    "        prec1 = accuracy(logit, Y_q, topk=(1,))\n",
    "        top1_val.update(prec1[0].item(), query_nums)\n",
    "        del val_optimizer\n",
    "        del model\n",
    "        if rank == 0:\n",
    "            print('Eposide-({0}): [{1}/{2}]\\t'\n",
    "                  'prec1 is {3}\\t'.format(epoch, task_num, 10, prec1[0].item()))\n",
    "    if rank == 0:        \n",
    "        print(\"第%d代测试结果为\"%epoch_item + str(top1_val.avg))\n",
    "    del top1_val\n",
    "##############################################################################\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    rank = opt.rank\n",
    "    opt.lr *= opt.world_size\n",
    "    batch_size = opt.batch_size\n",
    "    top1 = AverageMeter()\n",
    "    opt.outf, F_txt = set_save_path(opt)\n",
    "\n",
    "    global best_prec1, epoch_index\n",
    "    best_prec1 = 0\n",
    "    epoch_index = 0\n",
    "    \n",
    "    dataset = FewShotDataSet(data_dir)\n",
    "    dataset_length = len(dataset)\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset)\n",
    "    train_batch_sampler = torch.utils.data.BatchSampler(train_sampler, 64, drop_last=True)\n",
    "    nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, 8])  # number of workers\n",
    "    train_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                               batch_sampler=train_batch_sampler,\n",
    "                                               pin_memory=True,\n",
    "                                               num_workers=nw)\n",
    "    \n",
    "    \n",
    "    model = featureAugNet().to(device)\n",
    "    checkpoint_path = \"initial_weights.pt\"\n",
    "    if rank == 0:\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "    dist.barrier()\n",
    "    pretrain_path = \"\"\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[opt.gpu])\n",
    "#     model.load_state_dict(pretrain_state_dict)\n",
    "    criterion1 = nn.CrossEntropyLoss()\n",
    "    criterion2 = nn.MSELoss(reduction='sum')\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=opt.lr)\n",
    "#     optimizer.load_state_dict(torch.load(pretrain_path, map_location=device)['optimizer'])\n",
    "    print(opt)\n",
    "    print(opt, file=F_txt)\n",
    "#     print(model)\n",
    "    print(model, file=F_txt)\n",
    "\n",
    "    # ============================================ Training phase ========================================\n",
    "    print('===================================== Training on the train set =====================================')\n",
    "    print('===================================== Training on the train set =====================================',\n",
    "          file=F_txt)\n",
    "    print('Learning rate: %f' % opt.lr)\n",
    "    print('Learning rate: %f' % opt.lr, file=F_txt)\n",
    "\n",
    "    Train_losses = []\n",
    "    Val_losses = []\n",
    "    Test_losses = []\n",
    "\n",
    "    for epoch_item in range(1, 201):  # 0:50\n",
    "        print('==================== Epoch %d ====================' % epoch_item)\n",
    "        print('==================== Epoch %d ====================' % epoch_item, file=F_txt)\n",
    "        # ======================================= Loaders of Datasets =======================================\n",
    "        opt.current_epoch = epoch_item\n",
    "        train_sampler.set_epoch(epoch_item)\n",
    "        \n",
    "#         if epoch_item >20 and epoch_item < 26:\n",
    "#             optimizer.param_groups[0]['lr'] = 0.0001\n",
    "#             optimizer.param_groups[1]['lr'] = 0.01\n",
    "            \n",
    "        model.train()\n",
    "        train_loss = train(train_loader, model, [criterion1, criterion2], optimizer, 128, epoch_item, dataset_length, F_txt, device, rank)\n",
    "        Train_losses.append(train_loss)\n",
    "        print(\"################################### val ############################\")\n",
    "        model.eval()\n",
    "        acc = val(model, criterion1, epoch_item, rank)\n",
    "        print(\"################################### test ############################\")\n",
    "        test(model, criterion1, epoch_item, rank)\n",
    "        adjust_learning_rate(opt, optimizer, epoch_item, F_txt)\n",
    "        save_checkpoint(\n",
    "                {\n",
    "                    'epoch_index': epoch_item,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                }, os.path.join(opt.outf, 'epoch_tmp.pth.tar'))\n",
    "        if acc > best_prec1:\n",
    "            save_checkpoint(\n",
    "                {\n",
    "                    'epoch_index': epoch_item,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                }, os.path.join(opt.outf, 'best_model.pth.tar'))\n",
    "        if epoch_item % 20 == 0:\n",
    "            filename = os.path.join(opt.outf, 'save_epoch_%d.pth.tar' % epoch_item)\n",
    "            save_checkpoint(\n",
    "                {\n",
    "                    'epoch_index': epoch_item,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                }, filename)\n",
    "\n",
    "    print('======================================== Training is END ========================================\\n')\n",
    "    print('======================================== Training is END ========================================\\n',\n",
    "          file=F_txt)\n",
    "    F_txt.close()\n",
    "    if rank == 0:\n",
    "        if os.path.exists(checkpoint_path) is True:\n",
    "            os.remove(checkpoint_path)\n",
    "\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4747300,
     "sourceId": 8050197,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4747661,
     "sourceId": 8050733,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
